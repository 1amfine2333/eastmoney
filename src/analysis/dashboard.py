import akshare as ak
import pandas as pd
import yfinance as yf
import os
import glob
from datetime import datetime, timedelta
from typing import Dict, Any, List
import time
import threading

# Cache Setup
_DASHBOARD_CACHE = {}
_DASHBOARD_CACHE_LOCK = threading.Lock()
_DEFAULT_CACHE_TTL = 300  # 5 minutes

class DashboardService:
    def __init__(self, report_dir: str):
        self.report_dir = report_dir

    def _get_cached_data(self, key: str):
        with _DASHBOARD_CACHE_LOCK:
            if key in _DASHBOARD_CACHE:
                data, expiry = _DASHBOARD_CACHE[key]
                if time.time() < expiry:
                    return data
                else:
                    del _DASHBOARD_CACHE[key]
        return None

    def _set_cached_data(self, key: str, data: Any, duration: int = _DEFAULT_CACHE_TTL):
        with _DASHBOARD_CACHE_LOCK:
            _DASHBOARD_CACHE[key] = (data, time.time() + duration)

    def get_market_overview(self) -> Dict[str, Any]:
        """Section 1: Market Breadth, Indices, Turnover"""
        cache_key = "market_overview"
        cached = self._get_cached_data(cache_key)
        if cached: return cached

        data = {
            "indices": [],
            "breadth": {"up": 0, "down": 0, "flat": 0, "limit_up": 0, "limit_down": 0},
            "turnover": {"total": 0, "change_pct": 0, "change_amt": 0},
            "main_flow": 0
        }

        try:
            # 1. Indices (Shanghai, Shenzhen, ChiNext)
            # stock_zh_index_spot_em is the correct function
            indices_df = ak.stock_zh_index_spot_em()
            targets = ["ä¸Šè¯æŒ‡æ•°", "æ·±è¯æˆæŒ‡", "åˆ›ä¸šæ¿æŒ‡"]
            
            # This API returns a huge list, better filter by name
            if not indices_df.empty:
                for name in targets:
                    row = indices_df[indices_df['åç§°'] == name]
                    if not row.empty:
                        r = row.iloc[0]
                        data["indices"].append({
                            "name": name,
                            "price": r['æœ€æ–°ä»·'],
                            "change": r['æ¶¨è·Œå¹…']
                        })
            
            # 2. Turnover & Breadth
            # Breadth via Legu (Fast)
            try:
                legu_df = ak.stock_market_activity_legu()
                if not legu_df.empty:
                    # Convert to dict {item: value}
                    legu_map = dict(zip(legu_df['item'], legu_df['value']))
                    data["breadth"] = {
                        "up": int(float(legu_map.get("ä¸Šæ¶¨", 0))),
                        "down": int(float(legu_map.get("ä¸‹è·Œ", 0))),
                        "flat": int(float(legu_map.get("å¹³ç›˜", 0))),
                        "limit_up": int(float(legu_map.get("æ¶¨åœ", 0))),
                        "limit_down": int(float(legu_map.get("è·Œåœ", 0)))
                    }
            except Exception as e:
                print(f"Legu fetch failed: {e}")

            # Turnover via Indices (SH Composite + SZ Component/Composite)
            # We already fetched indices_df in step 1
            if not indices_df.empty:
                # Sum turnover of SH Composite (ä¸Šè¯æŒ‡æ•°) + SZ Component (æ·±è¯æˆæŒ‡)
                # Note: SZ Component is subset, SZ Composite (æ·±è¯ç»¼æŒ‡) is better but maybe not in main list?
                # Let's try to find "æ·±è¯ç»¼æŒ‡" first, else "æ·±è¯æˆæŒ‡"
                
                sh_row = indices_df[indices_df['åç§°'] == "ä¸Šè¯æŒ‡æ•°"]
                sz_row = indices_df[indices_df['åç§°'] == "æ·±è¯ç»¼æŒ‡"]
                if sz_row.empty:
                    sz_row = indices_df[indices_df['åç§°'] == "æ·±è¯æˆæŒ‡"]
                
                total_to = 0
                if not sh_row.empty:
                    total_to += float(sh_row.iloc[0]['æˆäº¤é¢'])
                if not sz_row.empty:
                    total_to += float(sz_row.iloc[0]['æˆäº¤é¢'])
                
                if total_to > 0:
                     # Convert to Billions (Yi)
                    data["turnover"]["total"] = round(total_to / 100000000, 2)
                
            # 3. Main Capital Flow
            # stock_individual_fund_flow_rank gives individual flows, sum top?
            # Or market level flow: stock_market_fund_flow
            try:
                flow_df = ak.stock_market_fund_flow()
                if not flow_df.empty:
                    # Usually returns historical data. Get last row
                    last = flow_df.iloc[-1]
                    data["main_flow"] = round(float(last.get('ä¸»åŠ›å‡€æµå…¥-å‡€é¢', 0)) / 100000000, 2)
            except:
                pass
                
        except Exception as e:
            print(f"Error fetching market overview: {e}")

        self._set_cached_data(cache_key, data)
        return data

    def get_gold_macro(self) -> Dict[str, Any]:
        """Section 2: Gold & Macro (YFinance)"""
        cache_key = "gold_macro"
        cached = self._get_cached_data(cache_key)
        if cached: return cached
        
        data = {"symbol": "GC=F", "price": 0, "change_pct": 0, "dxy": 0}
        try:
            # Gold
            gold = yf.Ticker("GC=F")
            hist = gold.history(period="2d")
            if not hist.empty:
                last = hist.iloc[-1]
                prev = hist.iloc[-2] if len(hist) > 1 else last
                data["price"] = round(last['Close'], 2)
                data["change_pct"] = round(((last['Close'] - prev['Close']) / prev['Close']) * 100, 2)
            
            # DXY
            dxy = yf.Ticker("DX-Y.NYB")
            hist_dxy = dxy.history(period="1d")
            if not hist_dxy.empty:
                data["dxy"] = round(hist_dxy.iloc[-1]['Close'], 2)
                
        except Exception as e:
            print(f"Error fetching gold/macro: {e}")
            
        self._set_cached_data(cache_key, data)
        return data

    def get_sectors(self) -> Dict[str, List]:
        """Section 3: Sector Performance"""
        cache_key = "sectors"
        cached = self._get_cached_data(cache_key)
        if cached: return cached
        
        result = {"gainers": [], "losers": []}
        try:
            df = ak.stock_board_industry_name_em()
            if not df.empty:
                # Sort by change
                sorted_df = df.sort_values(by='æ¶¨è·Œå¹…', ascending=False)
                
                # Top 10 Gainers
                for _, row in sorted_df.head(10).iterrows():
                    result["gainers"].append({
                        "name": row['æ¿å—åç§°'],
                        "change": row['æ¶¨è·Œå¹…'],
                        "flow": 0 # EM name API doesn't have flow, need merge or ignore
                    })
                
                # Top 10 Losers
                for _, row in sorted_df.tail(10).iterrows():
                    result["losers"].append({
                        "name": row['æ¿å—åç§°'],
                        "change": row['æ¶¨è·Œå¹…'],
                        "flow": 0
                    })
        except Exception as e:
            print(f"Error fetching sectors: {e}")
            
        self._set_cached_data(cache_key, result)
        return result

    def get_abnormal_movements(self) -> List[Dict]:
        """Section 4: Abnormal Movements (Stock Level Feed)"""
        cache_key = "abnormal_feed"
        cached = self._get_cached_data(cache_key)
        if cached: return cached
        
        moves = []
        try:
            # Fetch various types of real-time signals
            # Rocket (Rapid Rise), Dive (Rapid Fall), Limit Up, Limit Down
            targets = [
                ("ç«ç®­å‘å°„", "ðŸš€ æ‹‰å‡"), 
                ("é«˜å°è·³æ°´", "ðŸ“‰ è·³æ°´"),
                ("å°æ¶¨åœæ¿", "ðŸ”´ å°æ¶¨åœ"),
                ("å°è·Œåœæ¿", "ðŸŸ¢ å°è·Œåœ")
            ]
            
            for symbol, label in targets:
                try:
                    df = ak.stock_changes_em(symbol=symbol)
                    if not df.empty:
                        # Normalize columns if needed, usually they are consistent
                        for _, row in df.head(10).iterrows(): # Take top 10 of each type
                            moves.append({
                                "time": str(row.get('æ—¶é—´', '')),
                                "name": row.get('åç§°', ''),
                                "type": label,
                                "info": f"Code: {row.get('ä»£ç ')}"
                            })
                except Exception as sub_e:
                    print(f"Failed to fetch {symbol}: {sub_e}")

            # Sort by time descending (HH:MM:SS)
            # Filter out empty times just in case
            moves = [m for m in moves if m['time']]
            moves.sort(key=lambda x: x['time'], reverse=True)
            
        except Exception as e:
            print(f"Error fetching abnormal movements: {e}")
            
        # Cache for 30 seconds
        result = moves[:30]
        self._set_cached_data(cache_key, result, duration=30)
        return result

    def get_top_holdings_changes(self) -> List[Dict]:
        """Section 5: Top Capital Flow Stocks"""
        cache_key = "top_flow"
        cached = self._get_cached_data(cache_key)
        if cached: return cached
        
        stocks = []
        try:
            # Main capital flow rank
            df = ak.stock_individual_fund_flow_rank(indicator="ä»Šæ—¥")
            if not df.empty:
                # Top 10 inflow
                for _, row in df.head(10).iterrows():
                    stocks.append({
                        "code": str(row.get('ä»£ç ')),
                        "name": row.get('åç§°'),
                        "net_buy": round(float(row.get('ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢', 0)) / 100000000, 2), # Billions? usually units vary
                        "change_pct": row.get('ä»Šæ—¥æ¶¨è·Œå¹…')
                    })
        except Exception as e:
            print(f"Error flow: {e}")
            
        self._set_cached_data(cache_key, stocks)
        return stocks

    def get_system_stats(self) -> Dict[str, Any]:
        """Section 6: Report Generation Stats (Today)"""
        # No caching needed, file system is fast enough and we want realtime status
        today_str = datetime.now().strftime("%Y-%m-%d")
        
        stats = {
            "total": 0,
            "breakdown": {"pre": 0, "post": 0, "commodity": 0, "sentiment": 0},
            "latest": None
        }
        
        # Recursive search for .md files
        # Directories: reports/, reports/commodities/, reports/sentiment/
        # Pattern: YYYY-MM-DD*.md
        
        all_files = []
        
        # Root reports (Pre/Post)
        root_files = glob.glob(os.path.join(self.report_dir, f"{today_str}*.md"))
        all_files.extend([(f, 'root') for f in root_files])
        
        # Commodity
        comm_files = glob.glob(os.path.join(self.report_dir, "commodities", f"{today_str}*.md"))
        all_files.extend([(f, 'commodity') for f in comm_files])
        
        # Sentiment (Format: sentiment_YYYYMMDD...)
        sent_date = datetime.now().strftime("%Y%m%d")
        sent_files = glob.glob(os.path.join(self.report_dir, "sentiment", f"sentiment_{sent_date}*.md"))
        all_files.extend([(f, 'sentiment') for f in sent_files])
        
        stats["total"] = len(all_files)
        
        # Sort by mtime
        if all_files:
            all_files.sort(key=lambda x: os.path.getmtime(x[0]), reverse=True)
            stats["latest"] = os.path.basename(all_files[0][0])
            
            for f, loc in all_files:
                fname = os.path.basename(f)
                if loc == 'commodity':
                    stats["breakdown"]["commodity"] += 1
                elif loc == 'sentiment':
                    stats["breakdown"]["sentiment"] += 1
                elif "_pre_" in fname:
                    stats["breakdown"]["pre"] += 1
                elif "_post_" in fname:
                    stats["breakdown"]["post"] += 1
                    
        return stats

    def get_full_dashboard(self) -> Dict[str, Any]:
        """Aggregate all data"""
        return {
            "market_overview": self.get_market_overview(),
            "gold_macro": self.get_gold_macro(),
            "sectors": self.get_sectors(),
            "abnormal_movements": self.get_abnormal_movements(),
            "top_flows": self.get_top_holdings_changes(),
            "system_stats": self.get_system_stats()
        }
